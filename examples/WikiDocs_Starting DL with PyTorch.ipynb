{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"WikiDocs_Starting DL with PyTorch.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyO4SrI2BnCIgRLwQZHVASGx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"ec333db0ab584d95bb5e07b7beccac41":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a4fc1fac7774450da7b0a89d2cf1b8bc","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_ae65ffe678d04fb4bf4b35f7485225ea","IPY_MODEL_10b21a8fef094fbd82d2b5f71dcaaa43"]}},"a4fc1fac7774450da7b0a89d2cf1b8bc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ae65ffe678d04fb4bf4b35f7485225ea":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_4f978caad24a4e39a806530e24a326be","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":9912422,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":9912422,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_758e7bfc836d4d6bbab736af8cce6d1c"}},"10b21a8fef094fbd82d2b5f71dcaaa43":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_252236b8b47742d49f958abe9abec5fa","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 9913344/? [10:02&lt;00:00, 16450.99it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7758e559fb604c57af3ebdc175e98d48"}},"4f978caad24a4e39a806530e24a326be":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"758e7bfc836d4d6bbab736af8cce6d1c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"252236b8b47742d49f958abe9abec5fa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7758e559fb604c57af3ebdc175e98d48":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"41ee0bac3c5444caa4d4a26a0bb31604":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_4da83b8669c44782a24522a5fdbf64e7","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_c5a00e80949d4e02b209785aa9f2df4b","IPY_MODEL_dc613ec648234232a13caf536d860b37"]}},"4da83b8669c44782a24522a5fdbf64e7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c5a00e80949d4e02b209785aa9f2df4b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_2cf7462ddf14465296d13f5859a2996d","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":28881,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":28881,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_517a57809e224c80a53d244212740306"}},"dc613ec648234232a13caf536d860b37":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e528661c50a8445e95e0789d282041d0","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 29696/? [00:39&lt;00:00, 750.33it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e0937eae4f844d0aa0869a119512cc6c"}},"2cf7462ddf14465296d13f5859a2996d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"517a57809e224c80a53d244212740306":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e528661c50a8445e95e0789d282041d0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e0937eae4f844d0aa0869a119512cc6c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c7e4d743f8054d199d9de486141af790":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_8834d726910743f494c907cb6e20867b","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_6236099d182e457b8ff67f2b1007ff9b","IPY_MODEL_730ebdabec0b4d2da05b31e701bb52eb"]}},"8834d726910743f494c907cb6e20867b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6236099d182e457b8ff67f2b1007ff9b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_c95a7951c7f44a958fb6fef99992fbc3","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1648877,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1648877,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4256de469134460d950542d9275c7183"}},"730ebdabec0b4d2da05b31e701bb52eb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_6cd877f0fc074585ad65aa44a8cedb58","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1649664/? [00:38&lt;00:00, 42977.74it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3df8d82aadca42708ebb627e7bf1d692"}},"c95a7951c7f44a958fb6fef99992fbc3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"4256de469134460d950542d9275c7183":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6cd877f0fc074585ad65aa44a8cedb58":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3df8d82aadca42708ebb627e7bf1d692":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"09a3f64c553a404a9e4c03ff1ca507af":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_cb93965bd66d4ac4883d8c28729e7f65","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_ad6afd40a0ef4d25a734bb4978a10ca3","IPY_MODEL_abb4947d80614efc95773ae6936f2f5c"]}},"cb93965bd66d4ac4883d8c28729e7f65":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ad6afd40a0ef4d25a734bb4978a10ca3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_a55f871991d3405c9b0ca8b349b2e54f","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":4542,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":4542,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b629ec61402f458396139cdfe41a029a"}},"abb4947d80614efc95773ae6936f2f5c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_26e31c549c0e44238c5551a150d04a69","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 5120/? [04:33&lt;00:00, 18.69it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_428ba9c1a01b4b3a8c3b679f9cbf7cb5"}},"a55f871991d3405c9b0ca8b349b2e54f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"b629ec61402f458396139cdfe41a029a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"26e31c549c0e44238c5551a150d04a69":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"428ba9c1a01b4b3a8c3b679f9cbf7cb5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HhpHSPTgbH_4","executionInfo":{"status":"ok","timestamp":1630395547880,"user_tz":-540,"elapsed":3885,"user":{"displayName":"우태진","photoUrl":"","userId":"04263177752150657284"}},"outputId":"7b1648b5-050a-4b4b-c425-930d1d9ee2ab"},"source":["import torch\n","\n","t = torch.FloatTensor([0., 1., 2., 3., 4., 5., 6.])\n","\n","print(t.dim())\n","print(t.shape)\n","print(t.size())"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["1\n","torch.Size([7])\n","torch.Size([7])\n"]}]},{"cell_type":"code","metadata":{"id":"tyAIcaI2bXQ-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630395558327,"user_tz":-540,"elapsed":221,"user":{"displayName":"우태진","photoUrl":"","userId":"04263177752150657284"}},"outputId":"d42bdd62-5a42-4ac9-8bac-ee929792e59e"},"source":["import torch\n","\n","t = torch.FloatTensor([[[0, 1, 2],\n","                        [3, 4, 5]],\n","                        [[6, 7, 8],\n","                        [9, 10, 11]]])\n","print(t.shape)"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([2, 2, 3])\n"]}]},{"cell_type":"code","metadata":{"id":"YeOj_z0YmjJU"},"source":["# 02.04. class\n","\n","\n","class Calculator:\n","    # class: 여러 메서드들을 객체 형태로 독립적으로 생성할 수 있는 몰드같은 느낌\n","    def __init__(self): # __init__ 메서드: 파이썬에서 생성자로 자동 인식함\n","        self.result = 0\n","\n","    def add(self, num):\n","        # class 내부 함수: method 라고 부름\n","        self.result += num # 메서드에서 선언된 num: 객체 변수\n","        return self.result\n","\n","\n","cal1 = Calculator() # 선언한 cal1 객체: self 변수로 자동으로 정해짐\n","cal2 = Calculator()\n","\n","print(cal1.add(3)) # class.method() 호출 방식 사용\n","print(cal1.add(4))\n","print(cal2.add(3))\n","print(cal2.add(7))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hEU46W1bpeA5","executionInfo":{"status":"ok","timestamp":1628138784260,"user_tz":-540,"elapsed":581,"user":{"displayName":"우태진","photoUrl":"","userId":"04263177752150657284"}},"outputId":"5d03ba09-2925-4663-e656-7e9c9c931764"},"source":["# 03.04. nn.Module로 구현하는 선형 회귀\n","\n","import torch\n","\n","\n","# 항상 동일 결과가 나오게\n","torch.manual_seed(1)\n","\n","# 데이터\n","x_train = torch.FloatTensor([[73, 80, 75],\n","                             [93, 88, 93],\n","                             [89, 91, 90],\n","                             [96, 98, 100],\n","                             [73, 66, 70]])\n","y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])\n","\n","# 모델을 선언 및 초기화 / 단순 선형 회귀이므로 input_dim=1, output_dim=1\n","model = torch.nn.Linear(in_features=3, out_features=1, bias=True)\n","\n","# optimizer 설정 / 경사 하강법 SGD를 사용하고 learning rate를 의미하는 lr\n","optimizer = torch.optim.SGD(model.parameters(), lr=1e-5)\n","\n","# 전체 훈련 데이터에 대해 경사 하강법을 2,000회 반복\n","nb_epochs = 2_000\n","for epoch in range(nb_epochs + 1):\n","\n","    # H(x) 계산\n","    prediction = model(x_train)\n","\n","    # cost 계산 / 파이토치 제공 평균 제곱 오차 함수\n","    cost = torch.nn.functional.mse_loss(prediction, y_train)\n","\n","    # cost로 H(x) 개선하는 부분\n","    # gradient를 0으로 초기화\n","    optimizer.zero_grad()\n","\n","    # 비용 함수를 미분하여 gradient 계산\n","    # backward 연산\n","    cost.backward()\n","\n","    # W와 b를 업데이트\n","    optimizer.step()\n","\n","    # 100번마다 로그 출력\n","    if epoch % 100 == 0:\n","        print(f'Epoch {epoch}/{nb_epochs}, Cost: {cost.item():.6f}')\n","\n","# 학습 후 W 및 b 값 출력\n","print(list(model.parameters()))\n","\n","# 임의의 입력값 [73, 80, 75] 선언\n","new_x = torch.FloatTensor([[73, 80, 75]])\n","\n","# 임의의 입력값에 대해서 예측값 pred_y를 리턴받아서 저장 및 출력\n","pred_y = model(new_x)\n","print(f'예측값: {pred_y}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 0/2000, Cost: 31667.597656\n","Epoch 100/2000, Cost: 0.225993\n","Epoch 200/2000, Cost: 0.223911\n","Epoch 300/2000, Cost: 0.221941\n","Epoch 400/2000, Cost: 0.220059\n","Epoch 500/2000, Cost: 0.218271\n","Epoch 600/2000, Cost: 0.216575\n","Epoch 700/2000, Cost: 0.214950\n","Epoch 800/2000, Cost: 0.213413\n","Epoch 900/2000, Cost: 0.211952\n","Epoch 1000/2000, Cost: 0.210560\n","Epoch 1100/2000, Cost: 0.209232\n","Epoch 1200/2000, Cost: 0.207967\n","Epoch 1300/2000, Cost: 0.206761\n","Epoch 1400/2000, Cost: 0.205619\n","Epoch 1500/2000, Cost: 0.204522\n","Epoch 1600/2000, Cost: 0.203484\n","Epoch 1700/2000, Cost: 0.202485\n","Epoch 1800/2000, Cost: 0.201542\n","Epoch 1900/2000, Cost: 0.200635\n","Epoch 2000/2000, Cost: 0.199769\n","[Parameter containing:\n","tensor([[0.9778, 0.4539, 0.5768]], requires_grad=True), Parameter containing:\n","tensor([0.2802], requires_grad=True)]\n","예측값: tensor([[151.2305]], grad_fn=<AddmmBackward>)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4czQS8L2lV-W","executionInfo":{"status":"ok","timestamp":1628139532055,"user_tz":-540,"elapsed":598,"user":{"displayName":"우태진","photoUrl":"","userId":"04263177752150657284"}},"outputId":"9019378e-356a-491f-c7e1-558f5500ee09"},"source":["# 03.05 클래스로 파이토치 모델 구현하기\n","\n","import torch\n","\n","\n","# 항상 동일 결과가 나오게\n","torch.manual_seed(1)\n","\n","# 데이터\n","x_train = torch.FloatTensor([[73, 80, 75],\n","                             [93, 88, 93],\n","                             [89, 91, 90],\n","                             [96, 98, 100],\n","                             [73, 66, 70]])\n","y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])\n","\n","# torch.nn.Module을 상속받는 파이썬 클래스\n","class MultivariateLinearRegressionModel(torch.nn.Module):\n","    def __init__(self):\n","        # super() 함수는 상속하는 nn.Module 클래스의 속성을 가지고 초기화됨\n","        super().__init__()\n","        self.linear = torch.nn.Linear(3, 1)\n","\n","    def forward(self, x):\n","        return self.linear(x)\n","\n","\n","model = MultivariateLinearRegressionModel()\n","\n","optimizer = torch.optim.SGD(model.parameters(), lr=1e-5) \n","\n","# 전체 훈련 데이터에 대해 경사 하강법을 2,000회 반복\n","nb_epochs = 2_000\n","for epoch in range(nb_epochs + 1):\n","\n","    # H(x) 계산\n","    prediction = model(x_train)\n","\n","    # cost 계산 / 파이토치 제공 평균 제곱 오차 함수\n","    cost = torch.nn.functional.mse_loss(prediction, y_train)\n","\n","    # cost로 H(x) 개선하는 부분\n","    # gradient를 0으로 초기화\n","    optimizer.zero_grad()\n","\n","    # 비용 함수를 미분하여 gradient 계산\n","    # backward 연산\n","    cost.backward()\n","    \n","    # W와 b를 업데이트\n","    optimizer.step()\n","\n","    # 100번마다 로그 출력\n","    if epoch % 100 == 0:\n","        print(f'Epoch {epoch}/{nb_epochs}, Cost: {cost.item():.6f}')\n","\n","# 학습 후 W 및 b 값 출력\n","print(list(model.parameters()))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 0/2000, Cost: 31667.597656\n","Epoch 100/2000, Cost: 0.225993\n","Epoch 200/2000, Cost: 0.223911\n","Epoch 300/2000, Cost: 0.221941\n","Epoch 400/2000, Cost: 0.220059\n","Epoch 500/2000, Cost: 0.218271\n","Epoch 600/2000, Cost: 0.216575\n","Epoch 700/2000, Cost: 0.214950\n","Epoch 800/2000, Cost: 0.213413\n","Epoch 900/2000, Cost: 0.211952\n","Epoch 1000/2000, Cost: 0.210560\n","Epoch 1100/2000, Cost: 0.209232\n","Epoch 1200/2000, Cost: 0.207967\n","Epoch 1300/2000, Cost: 0.206761\n","Epoch 1400/2000, Cost: 0.205619\n","Epoch 1500/2000, Cost: 0.204522\n","Epoch 1600/2000, Cost: 0.203484\n","Epoch 1700/2000, Cost: 0.202485\n","Epoch 1800/2000, Cost: 0.201542\n","Epoch 1900/2000, Cost: 0.200635\n","Epoch 2000/2000, Cost: 0.199769\n","[Parameter containing:\n","tensor([[0.9778, 0.4539, 0.5768]], requires_grad=True), Parameter containing:\n","tensor([0.2802], requires_grad=True)]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hVp-IJ7Tqttn","executionInfo":{"status":"ok","timestamp":1628142217509,"user_tz":-540,"elapsed":357,"user":{"displayName":"우태진","photoUrl":"","userId":"04263177752150657284"}},"outputId":"c6f7daff-2795-4625-8396-d5ab1436c15b"},"source":["# 03.06. 미니 배치와 데이터 로드 (Mini Batch and Data Load)\n","\n","import torch\n","\n","\n","# epoch: 전체 훈련 데이터가 학습에 1번 사용된 주기\n","# iteration: 미니 배치 훈련 데이터가 학습이 1번 사용된 주기\n","\n","# 데이터\n","x_train = torch.FloatTensor([[73, 80, 75], \n","                             [93, 88, 93], \n","                             [89, 91, 90], \n","                             [96, 98, 100],   \n","                             [73, 66, 70]])  \n","y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])\n","\n","# 데이터셋 저장\n","dataset = torch.utils.data.TensorDataset(x_train, y_train)\n","\n","# 데이터셋 호출\n","dataloader = torch.utils.data.DataLoader(dataset=dataset, batch_size=2, shuffle=True)\n","\n","# 모델과 옵티마이저 설계\n","model = torch.nn.Linear(in_features=3, out_features=1, bias=True)\n","optimizer = torch.optim.SGD(model.parameters(), lr=1e-5)\n","\n","# 학습 시작\n","nb_epochs = 20\n","for epoch in range(nb_epochs + 1):\n","    for batch_idx, samples in enumerate(dataloader):\n","        # print(batch_idx)\n","        # print(samples)\n","        x_train, y_train = samples\n","\n","        # H(x) 계산\n","        prediction = model(x_train)\n","\n","        # cost 계산\n","        cost = torch.nn.functional.mse_loss(prediction, y_train)\n","\n","        # cost로 H(x) 계산\n","        optimizer.zero_grad()\n","        cost.backward()\n","        optimizer.step()\n","\n","        # 학습 결과 출력\n","        print(f'Epoch:{epoch}/{nb_epochs}, Batch:{batch_idx + 1}/{len(dataloader)}, Cost:{cost.item()}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch:0/20, Batch:1/3, Cost:40394.078125\n","Epoch:0/20, Batch:2/3, Cost:10625.84765625\n","Epoch:0/20, Batch:3/3, Cost:5451.56982421875\n","Epoch:1/20, Batch:1/3, Cost:937.502685546875\n","Epoch:1/20, Batch:2/3, Cost:265.94464111328125\n","Epoch:1/20, Batch:3/3, Cost:244.42251586914062\n","Epoch:2/20, Batch:1/3, Cost:3.5231244564056396\n","Epoch:2/20, Batch:2/3, Cost:55.83884811401367\n","Epoch:2/20, Batch:3/3, Cost:2.3711094856262207\n","Epoch:3/20, Batch:1/3, Cost:21.61503791809082\n","Epoch:3/20, Batch:2/3, Cost:1.5361597537994385\n","Epoch:3/20, Batch:3/3, Cost:23.620941162109375\n","Epoch:4/20, Batch:1/3, Cost:12.848325729370117\n","Epoch:4/20, Batch:2/3, Cost:17.57857894897461\n","Epoch:4/20, Batch:3/3, Cost:18.382184982299805\n","Epoch:5/20, Batch:1/3, Cost:11.40179443359375\n","Epoch:5/20, Batch:2/3, Cost:20.961008071899414\n","Epoch:5/20, Batch:3/3, Cost:28.93952751159668\n","Epoch:6/20, Batch:1/3, Cost:14.807928085327148\n","Epoch:6/20, Batch:2/3, Cost:2.5992140769958496\n","Epoch:6/20, Batch:3/3, Cost:33.501407623291016\n","Epoch:7/20, Batch:1/3, Cost:16.869901657104492\n","Epoch:7/20, Batch:2/3, Cost:24.529006958007812\n","Epoch:7/20, Batch:3/3, Cost:10.46108341217041\n","Epoch:8/20, Batch:1/3, Cost:8.686938285827637\n","Epoch:8/20, Batch:2/3, Cost:30.927562713623047\n","Epoch:8/20, Batch:3/3, Cost:7.897372722625732\n","Epoch:9/20, Batch:1/3, Cost:7.612912178039551\n","Epoch:9/20, Batch:2/3, Cost:18.70330238342285\n","Epoch:9/20, Batch:3/3, Cost:16.064273834228516\n","Epoch:10/20, Batch:1/3, Cost:12.797728538513184\n","Epoch:10/20, Batch:2/3, Cost:8.214152336120605\n","Epoch:10/20, Batch:3/3, Cost:23.461618423461914\n","Epoch:11/20, Batch:1/3, Cost:16.458566665649414\n","Epoch:11/20, Batch:2/3, Cost:8.302088737487793\n","Epoch:11/20, Batch:3/3, Cost:18.30076026916504\n","Epoch:12/20, Batch:1/3, Cost:3.977036714553833\n","Epoch:12/20, Batch:2/3, Cost:16.020421981811523\n","Epoch:12/20, Batch:3/3, Cost:29.2219295501709\n","Epoch:13/20, Batch:1/3, Cost:13.251001358032227\n","Epoch:13/20, Batch:2/3, Cost:15.146610260009766\n","Epoch:13/20, Batch:3/3, Cost:6.90296745300293\n","Epoch:14/20, Batch:1/3, Cost:20.339698791503906\n","Epoch:14/20, Batch:2/3, Cost:8.538605690002441\n","Epoch:14/20, Batch:3/3, Cost:4.5068745613098145\n","Epoch:15/20, Batch:1/3, Cost:9.943653106689453\n","Epoch:15/20, Batch:2/3, Cost:13.76618766784668\n","Epoch:15/20, Batch:3/3, Cost:19.03103256225586\n","Epoch:16/20, Batch:1/3, Cost:29.411712646484375\n","Epoch:16/20, Batch:2/3, Cost:15.6337251663208\n","Epoch:16/20, Batch:3/3, Cost:1.3668255805969238\n","Epoch:17/20, Batch:1/3, Cost:29.227428436279297\n","Epoch:17/20, Batch:2/3, Cost:8.651311874389648\n","Epoch:17/20, Batch:3/3, Cost:12.546140670776367\n","Epoch:18/20, Batch:1/3, Cost:2.676948308944702\n","Epoch:18/20, Batch:2/3, Cost:23.020742416381836\n","Epoch:18/20, Batch:3/3, Cost:20.121801376342773\n","Epoch:19/20, Batch:1/3, Cost:18.024099349975586\n","Epoch:19/20, Batch:2/3, Cost:9.444228172302246\n","Epoch:19/20, Batch:3/3, Cost:23.168087005615234\n","Epoch:20/20, Batch:1/3, Cost:21.232851028442383\n","Epoch:20/20, Batch:2/3, Cost:11.280956268310547\n","Epoch:20/20, Batch:3/3, Cost:14.621031761169434\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2hGz3nd80zJ1","executionInfo":{"status":"ok","timestamp":1628143217772,"user_tz":-540,"elapsed":295,"user":{"displayName":"우태진","photoUrl":"","userId":"04263177752150657284"}},"outputId":"4ffea4f7-551d-46bc-c72c-2a505aa9cbe2"},"source":["# 03.07. 커스텀 데이터셋 (Custom Dataset)\n","\n","import torch\n","\n","\n","# 커스텀 데이터셋 클래스\n","class CustomDataset(torch.utils.data.Dataset):\n","    # 데이터셋의 전처리를 해주는 부분\n","    def __init__(self):\n","        self.x_data = [[73, 80, 75],\n","                       [93, 88, 93],\n","                       [89, 91, 90],\n","                       [96, 98, 100],\n","                       [73, 66, 70]]\n","        self.y_data = [[152], [185], [180], [196], [142]]\n","\n","    # 데이터셋의 길이. 즉, 총 샘플의 수를 적어주는 부분\n","    def __len__(self):\n","        return len(self.x_data)\n","\n","    # 데이터셋에서 특정 1개의 샘플을 가져오는 함수\n","    def __getitem__(self, idx):\n","        x = torch.FloatTensor(self.x_data[idx])\n","        y = torch.FloatTensor(self.y_data[idx])\n","        return x, y\n","\n","\n","# 데이터 셋 저장\n","dataset = CustomDataset()\n","\n","# 데이터 셋 호출\n","dataloader = torch.utils.data.DataLoader(dataset=dataset, batch_size=2, shuffle=True)\n","\n","# 모델과 옵티마이저 설계\n","model = torch.nn.Linear(in_features=3, out_features=1, bias=True)\n","optimizer = torch.optim.SGD(model.parameters(), lr=1e-5)\n","\n","# 학습 시작\n","nb_epochs = 20\n","for epoch in range(nb_epochs + 1):\n","    for batch_idx, samples in enumerate(dataloader):\n","        # print(batch_idx)\n","        # print(samples)\n","        x_train, y_train = samples\n","\n","        # H(x) 계산\n","        prediction = model(x_train)\n","\n","        # cost 계산\n","        cost = torch.nn.functional.mse_loss(prediction, y_train)\n","\n","        # cost로 H(x) 계산\n","        optimizer.zero_grad()\n","        cost.backward()\n","        optimizer.step()\n","\n","        # 학습 결과 출력\n","        print(f'Epoch:{epoch}/{nb_epochs}, Batch:{batch_idx + 1}/{len(dataloader)}, Cost:{cost.item()}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch:0/20, Batch:1/3, Cost:40548.7421875\n","Epoch:0/20, Batch:2/3, Cost:7291.49462890625\n","Epoch:0/20, Batch:3/3, Cost:1811.4722900390625\n","Epoch:1/20, Batch:1/3, Cost:1189.89306640625\n","Epoch:1/20, Batch:2/3, Cost:401.4664306640625\n","Epoch:1/20, Batch:3/3, Cost:98.8622055053711\n","Epoch:2/20, Batch:1/3, Cost:59.92449188232422\n","Epoch:2/20, Batch:2/3, Cost:5.559006690979004\n","Epoch:2/20, Batch:3/3, Cost:0.0050149112939834595\n","Epoch:3/20, Batch:1/3, Cost:7.23870849609375\n","Epoch:3/20, Batch:2/3, Cost:0.5797872543334961\n","Epoch:3/20, Batch:3/3, Cost:9.432348251342773\n","Epoch:4/20, Batch:1/3, Cost:2.596285104751587\n","Epoch:4/20, Batch:2/3, Cost:6.112614154815674\n","Epoch:4/20, Batch:3/3, Cost:0.1735772043466568\n","Epoch:5/20, Batch:1/3, Cost:0.5858479142189026\n","Epoch:5/20, Batch:2/3, Cost:3.764530658721924\n","Epoch:5/20, Batch:3/3, Cost:4.496255874633789\n","Epoch:6/20, Batch:1/3, Cost:1.7508087158203125\n","Epoch:6/20, Batch:2/3, Cost:2.6920955181121826\n","Epoch:6/20, Batch:3/3, Cost:4.092446804046631\n","Epoch:7/20, Batch:1/3, Cost:0.8731223940849304\n","Epoch:7/20, Batch:2/3, Cost:3.5456326007843018\n","Epoch:7/20, Batch:3/3, Cost:4.466667175292969\n","Epoch:8/20, Batch:1/3, Cost:2.9434218406677246\n","Epoch:8/20, Batch:2/3, Cost:2.7870290279388428\n","Epoch:8/20, Batch:3/3, Cost:3.619434356689453\n","Epoch:9/20, Batch:1/3, Cost:3.126628875732422\n","Epoch:9/20, Batch:2/3, Cost:3.2851402759552\n","Epoch:9/20, Batch:3/3, Cost:3.6716420650482178\n","Epoch:10/20, Batch:1/3, Cost:4.018427848815918\n","Epoch:10/20, Batch:2/3, Cost:3.578518867492676\n","Epoch:10/20, Batch:3/3, Cost:4.788361072540283\n","Epoch:11/20, Batch:1/3, Cost:2.840890407562256\n","Epoch:11/20, Batch:2/3, Cost:1.5299477577209473\n","Epoch:11/20, Batch:3/3, Cost:5.260715007781982\n","Epoch:12/20, Batch:1/3, Cost:2.605294704437256\n","Epoch:12/20, Batch:2/3, Cost:2.249572515487671\n","Epoch:12/20, Batch:3/3, Cost:4.657313823699951\n","Epoch:13/20, Batch:1/3, Cost:2.9265642166137695\n","Epoch:13/20, Batch:2/3, Cost:1.5157766342163086\n","Epoch:13/20, Batch:3/3, Cost:4.3023200035095215\n","Epoch:14/20, Batch:1/3, Cost:0.5003498196601868\n","Epoch:14/20, Batch:2/3, Cost:6.0373334884643555\n","Epoch:14/20, Batch:3/3, Cost:4.1231255531311035\n","Epoch:15/20, Batch:1/3, Cost:1.3431631326675415\n","Epoch:15/20, Batch:2/3, Cost:3.55239200592041\n","Epoch:15/20, Batch:3/3, Cost:4.573134422302246\n","Epoch:16/20, Batch:1/3, Cost:3.1721320152282715\n","Epoch:16/20, Batch:2/3, Cost:3.901103973388672\n","Epoch:16/20, Batch:3/3, Cost:5.27998161315918\n","Epoch:17/20, Batch:1/3, Cost:2.1210837364196777\n","Epoch:17/20, Batch:2/3, Cost:3.0048673152923584\n","Epoch:17/20, Batch:3/3, Cost:5.418176651000977\n","Epoch:18/20, Batch:1/3, Cost:2.273881673812866\n","Epoch:18/20, Batch:2/3, Cost:2.8609280586242676\n","Epoch:18/20, Batch:3/3, Cost:3.7225160598754883\n","Epoch:19/20, Batch:1/3, Cost:3.0667877197265625\n","Epoch:19/20, Batch:2/3, Cost:3.0348315238952637\n","Epoch:19/20, Batch:3/3, Cost:0.8328344821929932\n","Epoch:20/20, Batch:1/3, Cost:2.0183866024017334\n","Epoch:20/20, Batch:2/3, Cost:6.400998115539551\n","Epoch:20/20, Batch:3/3, Cost:0.8175596594810486\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9J--mw9c5UXv","executionInfo":{"status":"ok","timestamp":1628145481321,"user_tz":-540,"elapsed":623,"user":{"displayName":"우태진","photoUrl":"","userId":"04263177752150657284"}},"outputId":"d5e2290a-1b46-49ca-ab34-a501faacfce4"},"source":["# 04.02. nn.Module로 구현하는 로지스틱 회귀\n","\n","import torch\n","\n","\n","# 일정한 결과 도출\n","torch.manual_seed(1)\n","\n","# 훈련 데이터\n","x_data = [[1, 2], [2, 3], [3, 1], [4, 3], [5, 3], [6, 2]]\n","y_data = [[0], [0], [0], [1], [1], [1]]\n","x_train = torch.FloatTensor(x_data)\n","y_train = torch.FloatTensor(y_data)\n","\n","# 모듈 층 쌓기\n","model = torch.nn.Sequential(torch.nn.Linear(in_features=2, out_features=1, bias=True),\n","                            torch.nn.Sigmoid())\n","\n","# optimizer 설정\n","optimizer = torch.optim.SGD(model.parameters(), lr=1)\n","\n","# 학습 시작\n","nb_epochs = 1_000\n","for epoch in range(nb_epochs + 1):\n","\n","    # H(x) 계산\n","    hypothesis = model(x_train)\n","\n","    # cost 계산\n","    cost = torch.nn.functional.binary_cross_entropy(hypothesis, y_train)\n","\n","    # cost로 H(x) 개선\n","    optimizer.zero_grad()\n","    cost.backward()\n","    optimizer.step()\n","\n","    # 20번마다 로그 출력\n","    if epoch % 100 == 0:\n","\n","        # 예측값이 0.5를 넘으면 True로 간주\n","        prediction = hypothesis >= torch.FloatTensor([0.5])\n","\n","        # 실제값과 일치하는 경우만 True로 간주\n","        correct_prediction = prediction.float() == y_train\n","\n","        # 정확도를 계산\n","        accuracy = correct_prediction.sum().item() / len(correct_prediction)\n","\n","        # 학습 결과 출력\n","        print(f'Epoch:{epoch}/{nb_epochs}, Cost:{cost.item()}, Accuracy:{accuracy * 100}')\n","\n","print(list(model.parameters()))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch:0/1000, Cost:0.5397130846977234, Accuracy:83.33333333333334\n","Epoch:100/1000, Cost:0.1342717856168747, Accuracy:100.0\n","Epoch:200/1000, Cost:0.08048570901155472, Accuracy:100.0\n","Epoch:300/1000, Cost:0.05782029405236244, Accuracy:100.0\n","Epoch:400/1000, Cost:0.045251354575157166, Accuracy:100.0\n","Epoch:500/1000, Cost:0.037228479981422424, Accuracy:100.0\n","Epoch:600/1000, Cost:0.0316491425037384, Accuracy:100.0\n","Epoch:700/1000, Cost:0.027538282796740532, Accuracy:100.0\n","Epoch:800/1000, Cost:0.024380534887313843, Accuracy:100.0\n","Epoch:900/1000, Cost:0.021877193823456764, Accuracy:100.0\n","Epoch:1000/1000, Cost:0.019843030720949173, Accuracy:100.0\n","[Parameter containing:\n","tensor([[3.2534, 1.5181]], requires_grad=True), Parameter containing:\n","tensor([-14.4839], requires_grad=True)]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":828,"referenced_widgets":["ec333db0ab584d95bb5e07b7beccac41","a4fc1fac7774450da7b0a89d2cf1b8bc","ae65ffe678d04fb4bf4b35f7485225ea","10b21a8fef094fbd82d2b5f71dcaaa43","4f978caad24a4e39a806530e24a326be","758e7bfc836d4d6bbab736af8cce6d1c","252236b8b47742d49f958abe9abec5fa","7758e559fb604c57af3ebdc175e98d48","41ee0bac3c5444caa4d4a26a0bb31604","4da83b8669c44782a24522a5fdbf64e7","c5a00e80949d4e02b209785aa9f2df4b","dc613ec648234232a13caf536d860b37","2cf7462ddf14465296d13f5859a2996d","517a57809e224c80a53d244212740306","e528661c50a8445e95e0789d282041d0","e0937eae4f844d0aa0869a119512cc6c","c7e4d743f8054d199d9de486141af790","8834d726910743f494c907cb6e20867b","6236099d182e457b8ff67f2b1007ff9b","730ebdabec0b4d2da05b31e701bb52eb","c95a7951c7f44a958fb6fef99992fbc3","4256de469134460d950542d9275c7183","6cd877f0fc074585ad65aa44a8cedb58","3df8d82aadca42708ebb627e7bf1d692","09a3f64c553a404a9e4c03ff1ca507af","cb93965bd66d4ac4883d8c28729e7f65","ad6afd40a0ef4d25a734bb4978a10ca3","abb4947d80614efc95773ae6936f2f5c","a55f871991d3405c9b0ca8b349b2e54f","b629ec61402f458396139cdfe41a029a","26e31c549c0e44238c5551a150d04a69","428ba9c1a01b4b3a8c3b679f9cbf7cb5"]},"id":"dOg1vfAYB-UG","executionInfo":{"status":"ok","timestamp":1628147003550,"user_tz":-540,"elapsed":452011,"user":{"displayName":"우태진","photoUrl":"","userId":"04263177752150657284"}},"outputId":"56877884-da2e-4e6a-edaf-ff8306605cdc"},"source":["# 05.05 소프트맥스 회귀로 MNIST 데이터 분류하기\n","\n","import torch\n","import torchvision.datasets as dsets\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader\n","import torch.nn as nn\n","import matplotlib.pyplot as plt\n","import random\n","\n","\n","# GPU 사용\n","USE_CUDA = torch.cuda.is_available()\n","device = torch.device('cuda' if USE_CUDA else 'cpu')\n","print(f'다음 기기로 학습합니다: {device}')\n","\n","# for reproducibility\n","random.seed(777)\n","torch.manual_seed(777)\n","if device == 'cuda':\n","    torch.cuda.manual_seed_all(777)\n","\n","# hyperparameters\n","training_epochs = 15\n","batch_size = 100\n","\n","# MNIST dataset\n","mnist_train = dsets.MNIST(root='MNIST_data/',\n","                          train=True,\n","                          transform=transforms.ToTensor(),\n","                          download=True)\n","\n","mnist_test = dsets.MNIST(root='MNIST_data/',\n","                         train=False,\n","                         transform=transforms.ToTensor(),\n","                         download=True)\n","\n","# dataset loader\n","data_loader = DataLoader(dataset=mnist_train,\n","                         batch_size=batch_size,\n","                         shuffle=True,\n","                         drop_last=True)\n","\n","# MNIST data image of shape 28 x 28 = 784\n","linear = nn.Linear(784, 10, bias=True).to(device)\n","\n","# 비용 함수와 옵티마이저 정의\n","# 내부적으로 소프트맥스 함수를 포함하고 있음\n","criterion = nn.CrossEntropyLoss().to(device)\n","optimizer = torch.optim.SGD(linear.parameters(), lr=0.1)\n","\n","# 학습 시작\n","for epoch in range(training_epochs):\n","    avg_cost = 0\n","    total_batch = len(data_loader)\n","\n","    for X, Y in data_loader:\n","        \n","        # 배치 크기가 100이므로 아래의 연산에서 X는 (100, 784)의 텐서\n","        X = X.view(-1, 28 * 28).to(device)\n","        \n","        # 레이블은 원-핫 인코딩이 된 상태가 아니라 0 ~ 9의 정수\n","        Y = Y.to(device)\n","\n","        optimizer.zero_grad()\n","        hypothesis = linear(X)\n","        cost = criterion(hypothesis, Y)\n","        cost.backward()\n","        optimizer.step()\n","\n","        avg_cost += cost / total_batch\n","\n","    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n","\n","print('Learning finished')\n","\n","# 테스트 데이터를 사용하여 모델을 테스트\n","# torch.no_grad()를 하면 gradient 계산을 수행하지 않음\n","with torch.no_grad():\n","    X_test = mnist_test.test_data.view(-1, 28 * 28).float().to(device)\n","    Y_test = mnist_test.test_labels.to(device)\n","\n","    prediction = linear(X_test)\n","    correct_prediction = torch.argmax(prediction, 1) == Y_test\n","    accuracy = correct_prediction.float().mean()\n","    print('Accuracy:', accuracy.item())\n","\n","    # MNIST 테스트 데이터에서 무작위로 하나를 뽑아서 예측\n","    r = random.randint(0, len(mnist_test) - 1)\n","    X_single_data = mnist_test.test_data[r:r + 1].view(-1, 28 * 28).float().to(device)\n","    Y_single_data = mnist_test.test_labels[r:r + 1].to(device)\n","\n","    print('Label: ', Y_single_data.item())\n","    single_prediction = linear(X_single_data)\n","    print('Prediction: ', torch.argmax(single_prediction, 1).item())\n","\n","    plt.imshow(mnist_test.test_data[r:r + 1].view(28, 28), cmap='Greys', interpolation='nearest')\n","    plt.show()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["다음 기기로 학습합니다: cuda\n","Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ec333db0ab584d95bb5e07b7beccac41","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=9912422.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Extracting MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz to MNIST_data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"41ee0bac3c5444caa4d4a26a0bb31604","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=28881.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Extracting MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c7e4d743f8054d199d9de486141af790","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=1648877.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Extracting MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz to MNIST_data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"09a3f64c553a404a9e4c03ff1ca507af","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=4542.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Extracting MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n","  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 0001 cost = 0.535150588\n","Epoch: 0002 cost = 0.359577715\n","Epoch: 0003 cost = 0.331264228\n","Epoch: 0004 cost = 0.316404670\n","Epoch: 0005 cost = 0.307106942\n","Epoch: 0006 cost = 0.300456554\n","Epoch: 0007 cost = 0.294933408\n","Epoch: 0008 cost = 0.290956199\n","Epoch: 0009 cost = 0.287074089\n","Epoch: 0010 cost = 0.284515619\n","Epoch: 0011 cost = 0.281914026\n","Epoch: 0012 cost = 0.279526860\n","Epoch: 0013 cost = 0.277636588\n","Epoch: 0014 cost = 0.275874794\n","Epoch: 0015 cost = 0.274422735\n","Learning finished\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CPVpELfMIf1d","executionInfo":{"status":"ok","timestamp":1628152082428,"user_tz":-540,"elapsed":86117,"user":{"displayName":"우태진","photoUrl":"","userId":"04263177752150657284"}},"outputId":"233f9f65-522e-48a2-a394-d4b2789973a5"},"source":["# 07.03. 깊은 CNN으로 MNIST 분류하기\n","\n","# Import all libraries\n","import torch\n","import torchvision.datasets as dsets\n","import torchvision.transforms as transforms\n","import torch.nn.init\n","\n","\n","# Using GPU\n","if torch.cuda.is_available():\n","    device = 'cuda'\n","else:\n","    device = 'cpu'\n","\n","# 랜덤 시드 고정\n","torch.manual_seed(777)\n","\n","# GPU 사용 가능일 경우 랜덤 시드 고정\n","if device == 'cuda':\n","    torch.cuda.manual_seed_all(777)\n","\n","# 학습 파라미터 설정\n","learning_rate = 0.001\n","training_epochs = 15\n","batch_size = 100\n","\n","# 데이터 셋 정의\n","mnist_train = dsets.MNIST(root='MNIST_data/', # 다운로드 경로 지정\n","                          train=True, # True를 지정하면 훈련 데이터로 다운로드\n","                          transform=transforms.ToTensor(), # 텐서로 변환\n","                          download=True)\n","\n","mnist_test = dsets.MNIST(root='MNIST_data/', # 다운로드 경로 지정\n","                         train=False, # False를 지정하면 테스트 데이터로 다운로드\n","                         transform=transforms.ToTensor(), # 텐서로 변환\n","                         download=True)\n","\n","# 데이터 로드 정의\n","data_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n","                                          batch_size=batch_size,\n","                                          shuffle=True,\n","                                          drop_last=True)\n","\n","# 모델 클래스 정의\n","class CNN(torch.nn.Module):\n","    def __init__(self):\n","        super(CNN, self).__init__()\n","        self.keep_prob = 0.5\n","        # L1 ImgIn shape=(?, 28, 28, 1)\n","        #    Conv     -> (?, 28, 28, 32)\n","        #    Pool     -> (?, 14, 14, 32)\n","        self.layer1 = torch.nn.Sequential(torch.nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n","                                          torch.nn.ReLU(),\n","                                          torch.nn.MaxPool2d(kernel_size=2, stride=2))\n","\n","        # L2 ImgIn shape=(?, 14, 14, 32)\n","        #    Conv      ->(?, 14, 14, 64)\n","        #    Pool      ->(?, 7, 7, 64)\n","        self.layer2 = torch.nn.Sequential(torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n","                                          torch.nn.ReLU(),\n","                                          torch.nn.MaxPool2d(kernel_size=2, stride=2))\n","\n","        # L3 ImgIn shape=(?, 7, 7, 64)\n","        #    Conv      ->(?, 7, 7, 128)\n","        #    Pool      ->(?, 4, 4, 128)\n","        self.layer3 = torch.nn.Sequential(torch.nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n","                                          torch.nn.ReLU(),\n","                                          torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=1))\n","\n","        # L4 FC 4x4x128 inputs -> 625 outputs\n","        self.fc1 = torch.nn.Linear(4 * 4 * 128, 625, bias=True)\n","        torch.nn.init.xavier_uniform_(self.fc1.weight)\n","        self.layer4 = torch.nn.Sequential(self.fc1,\n","                                          torch.nn.ReLU(),\n","                                          torch.nn.Dropout(p=1 - self.keep_prob))\n","\n","        # L5 Final FC 625 inputs -> 10 outputs\n","        self.fc2 = torch.nn.Linear(625, 10, bias=True)\n","        torch.nn.init.xavier_uniform_(self.fc2.weight)\n","\n","    def forward(self, x):\n","        out = self.layer1(x)\n","        out = self.layer2(out)\n","        out = self.layer3(out)\n","        out = out.view(out.size(0), -1) # Flatten for FCL\n","        out = self.layer4(out)\n","        out = self.fc2(out)\n","        return out\n","\n","\n","# CNN 모델 정의\n","model = CNN().to(device)\n","\n","# 비용 함수와 옵티마이저 정의\n","# 비용 함수에 소프트맥스 함수 포함\n","criterion = torch.nn.CrossEntropyLoss().to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","# 총 배치 수 정의\n","total_batch = len(data_loader)\n","\n","# 학습 시작\n","for epoch in range(training_epochs):\n","    avg_cost = 0\n","\n","    # 미니 배치 단위로 호출, X: 미니 배치, Y: 레이블\n","    for X, Y in data_loader:\n","        # image is already size of (28x28), no reshape\n","        # label is not one-hot encoded\n","        X = X.to(device)\n","        Y = Y.to(device)\n","\n","        optimizer.zero_grad()\n","        hypothesis = model(X)\n","        cost = criterion(hypothesis, Y)\n","        cost.backward()\n","        optimizer.step()\n","\n","        avg_cost += cost / total_batch\n","\n","    # 학습 결과 출력\n","    print(f'[Epoch: {epoch + 1}], Cost: {avg_cost:0.3f}')\n","\n","# 테스트 진행\n","# 학습을 진행하지 않을 것이므로 torch.no_grad()\n","with torch.no_grad():\n","    X_test = mnist_test.test_data.view(len(mnist_test), 1, 28, 28).float().to(device)\n","    Y_test = mnist_test.test_labels.to(device)\n","\n","    prediction = model(X_test)\n","    correct_prediction = torch.argmax(prediction, 1) == Y_test\n","    accuracy = correct_prediction.float().mean()\n","    print('Accuracy:', accuracy.item())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[Epoch: 1], Cost: 0.191\n","[Epoch: 2], Cost: 0.054\n","[Epoch: 3], Cost: 0.036\n","[Epoch: 4], Cost: 0.029\n","[Epoch: 5], Cost: 0.024\n","[Epoch: 6], Cost: 0.021\n","[Epoch: 7], Cost: 0.017\n","[Epoch: 8], Cost: 0.016\n","[Epoch: 9], Cost: 0.012\n","[Epoch: 10], Cost: 0.013\n","[Epoch: 11], Cost: 0.011\n","[Epoch: 12], Cost: 0.010\n","[Epoch: 13], Cost: 0.009\n","[Epoch: 14], Cost: 0.008\n","[Epoch: 15], Cost: 0.006\n","Accuracy: 0.9815999865531921\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:67: UserWarning: test_data has been renamed data\n","  warnings.warn(\"test_data has been renamed data\")\n","/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:57: UserWarning: test_labels has been renamed targets\n","  warnings.warn(\"test_labels has been renamed targets\")\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"fXyn6_-8XLmE"},"source":[""],"execution_count":null,"outputs":[]}]}