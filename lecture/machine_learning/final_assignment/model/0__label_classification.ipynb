{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"iKqY7qXW3-OX"},"outputs":[],"source":["import pandas as pd\n","from konlpy.tag import Okt\n","import pickle\n","from tqdm import tqdm\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.svm import SVC\n","from sklearn.pipeline import Pipeline\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import classification_report\n","import numpy as np\n","from imblearn.under_sampling import RandomUnderSampler\n","from imblearn.over_sampling import RandomOverSampler\n","import numpy as np\n","\n","tqdm.pandas()"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"ObV-a-on5Urf"},"outputs":[],"source":["def tokenizer(text):\n","    # divide Korean text into morpheme units\n","    okt = Okt()\n","\n","    return okt.morphs(text)"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"lwEj-IxL0ZOj"},"outputs":[],"source":["def load_data(path):\n","    df = pd.read_csv(path)\n","    # get only label column equals 0 or 1\n","    df = df[df.label != 2]\n","    df = df[df.label != 11]\n","\n","    text_list = df[\"sentence\"].tolist()\n","    label_list = df[\"label\"].tolist()\n","\n","    return text_list, label_list"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"L-dOpE2Dr9Vy"},"outputs":[],"source":["def split(text_list, label_list):\n","    text_train, text_test, label_train, label_test = train_test_split(text_list, label_list, test_size=0.2)\n","\n","    return text_train, text_test, label_train, label_test"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"VqlZa0Nms_Rs"},"outputs":[],"source":["def learn(X_train, X_test, y_train, y_test, model):\n","    # extract text feature with TfidfVectorizer\n","    tfidf = TfidfVectorizer(lowercase=False, tokenizer=tokenizer)\n","    # set linear support vector classifier\n","    svm = SVC(kernel=\"linear\", probability=True)\n","    # set an object containing overall processes\n","    pipe = Pipeline([(\"vect\", tfidf), (\"clf\", svm)])\n","\n","    pipe.fit(X_train, y_train)\n","    y_pred = pipe.predict(X_test)\n","\n","    # get performance metrics\n","    print(f\"Test acc: \\n {accuracy_score(y_test, y_pred):.2f}\")\n","    print(f\"CLS report: \\n {classification_report(y_test, y_pred)}\")\n","\n","    # save model\n","    with open(model, \"wb\") as f:\n","        pickle.dump(pipe, f)\n","\n","    print(\"Model Saved\")"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"WQwGCV8_uL5J"},"outputs":[],"source":["def test(model):\n","    # get saved model\n","    with open(model, \"rb\") as f:\n","        pipe = pickle.load(f)\n","\n","    while True:\n","        text = input(\"Please write report: \")\n","        if text == \"end\":\n","            break\n","\n","        str = [text]\n","        # get probability for each class\n","        r1 = np.max(pipe.predict_proba(str) * 100)\n","        # get prediction\n","        r2 = pipe.predict(str)[0]\n","\n","        print(\"Acc: \", r1)\n","        print(r2)"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"5kl2MFJs1fe0"},"outputs":[],"source":["def tonumpy(text_list, label_list):\n","    # convert list to array\n","    X_imb, y_imb = np.array(text_list), np.array(label_list)\n","    X_imb, y_imb = X_imb.reshape((-1, 1)), y_imb.reshape((-1, 1))\n","\n","    return X_imb, y_imb"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"4Bk8M6zu1_oJ"},"outputs":[],"source":["def tolist(X_samp):\n","    # convert array to list\n","    a = []\n","    for i in tqdm(X_samp):\n","        a.append(i[0])\n","\n","    return a"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"5xGC0VxTvSjk"},"outputs":[],"source":["def under_sampling(text_list, label_list):\n","    X_imb, y_imb = tonumpy(text_list, label_list)\n","    # sampling method that reduces the number of data in a class with a lot of data\n","    X_samp, y_samp = RandomUnderSampler(random_state=0).fit_resample(X_imb, y_imb)\n","\n","    return tolist(X_samp), y_samp.tolist()"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"nCZXNloB5YYQ"},"outputs":[],"source":["def over_sampling(text_list, label_list):\n","    X_imb, y_imb = tonumpy(text_list, label_list)\n","    # sampling method that increases the number of data of a class with less data\n","    X_samp, y_samp = RandomOverSampler(random_state=0).fit_resample(X_imb, y_imb)\n","\n","    return tolist(X_samp), y_samp.tolist()"]},{"cell_type":"code","execution_count":34,"metadata":{"id":"zwh5YSWp2eKa"},"outputs":[],"source":["def train(path, model, mode: str):\n","    # return text: list and label: list\n","    text, label = load_data(path)\n","\n","    # select under or over sampling\n","    if mode == \"under_sampling\":\n","        text, label = under_sampling(text, label)\n","    if mode == \"over_sampling\":\n","        text, label = over_sampling(text, label)\n","\n","    # split dataset train and test set\n","    text_train, text_test, label_train, label_test = split(text, label)\n","    learn(text_train, text_test, label_train, label_test, model)"]},{"cell_type":"code","execution_count":49,"metadata":{"id":"g6VsjQK79vux"},"outputs":[],"source":["def label_csv(model: str, unlabeled_path: str, save_path: str):\n","    # get unlabeled dataset\n","    df = pd.read_csv(unlabeled_path)\n","    # remove missing values\n","    df = df[df[\"sentence\"].notna()]\n","    df = df[df[\"fixed\"].notna()]\n","\n","    # load model pipeline\n","    with open(model, \"rb\") as f:\n","        pipe = pickle.load(f)\n","\n","    p_label = []\n","    p_proba = []\n","\n","    text_list = df[\"fixed\"].tolist()\n","    for text in tqdm(text_list):\n","        if text is not None:\n","            str = [text]\n","        p_proba.append(np.max(pipe.predict_proba(str) * 100))\n","        p_label.append(pipe.predict(str)[0])\n","\n","    df[\"label\"] = p_label\n","    df[\"probability\"] = p_proba\n","\n","    df.to_csv(save_path, index=False, encoding=\"utf-8\")\n","    print(\"Saved pseudo labeled .csv file\")"]},{"cell_type":"code","execution_count":37,"metadata":{"id":"gxOQmX6CMPiO"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","      <th>sentence</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>창문 구조 자체가 방음이 잘 되지 않고 찬바람이 들어오는 것 같아요.</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>지금 새벽 네시가 다 되어 가는데 밖에 경찰차 소리가 엄청나게 크게 들리네요?.</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>난방도 기능은 존재하는데 되는지를 모르겠네요.</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>별로 춥지 않아서 컴플레인은 걸지 않았지만 겨울철 되면 문제가 커질 것 같고요.</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>그리고 화장실 문이 심하게 덜 렁거리고 콘센트가 거의 없어서 매우 불편했습니다.</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   label                                      sentence\n","0      0        창문 구조 자체가 방음이 잘 되지 않고 찬바람이 들어오는 것 같아요.\n","1      0  지금 새벽 네시가 다 되어 가는데 밖에 경찰차 소리가 엄청나게 크게 들리네요?.\n","2      0                     난방도 기능은 존재하는데 되는지를 모르겠네요.\n","3      0  별로 춥지 않아서 컴플레인은 걸지 않았지만 겨울철 되면 문제가 커질 것 같고요.\n","4      0  그리고 화장실 문이 심하게 덜 렁거리고 콘센트가 거의 없어서 매우 불편했습니다."]},"execution_count":37,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.read_csv(\"../database/review_3_handlabeled.csv\", index_col=None)\n","df[:5]"]},{"cell_type":"code","execution_count":38,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":156358,"status":"ok","timestamp":1620782581546,"user":{"displayName":"이재리","photoUrl":"","userId":"07799536652921530236"},"user_tz":-540},"id":"MYt2S5le8Rvl","outputId":"245f2d43-96f4-4061-d4ff-052295e8846e"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 64674/64674 [00:00<00:00, 878031.02it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Test acc: \n"," 0.96\n","CLS report: \n","               precision    recall  f1-score   support\n","\n","           0       0.94      0.99      0.96      6491\n","           1       0.98      0.94      0.96      6444\n","\n","    accuracy                           0.96     12935\n","   macro avg       0.96      0.96      0.96     12935\n","weighted avg       0.96      0.96      0.96     12935\n","\n","Model Saved\n"]}],"source":["# training step with over sampling\n","train(path=\"../database/review_3_handlabeled.csv\", model=\"over.pkl\", mode=\"over_sampling\")"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 15150/15150 [00:00<00:00, 802836.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Test acc: \n"," 0.93\n","CLS report: \n","               precision    recall  f1-score   support\n","\n","           0       0.91      0.96      0.93      1502\n","           1       0.96      0.90      0.93      1528\n","\n","    accuracy                           0.93      3030\n","   macro avg       0.93      0.93      0.93      3030\n","weighted avg       0.93      0.93      0.93      3030\n","\n","Model Saved\n"]}],"source":["# training step with under sampling\n","train(path=\"../database/review_3_handlabeled.csv\", model=\"under.pkl\", mode=\"under_sampling\")"]},{"cell_type":"code","execution_count":50,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 154031/154031 [19:45<00:00, 129.90it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Saved pseudo labeled .csv file\n"]}],"source":["# write overall file with label\n","label_csv(model=\"../model/over.pkl\", unlabeled_path=\"../database/review_3_naver.csv\", save_path=\"../database/review_pseudolabeled.csv\")"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMDvaSBFgzGS5n4rKGUq8+X","collapsed_sections":[],"mount_file_id":"1pAFRAnoENjvVpXVLwKwdEXjVvMKX6H2J","name":"label.ipynb","provenance":[{"file_id":"1YdGp_lYv8DQL9RXWXuGs6896xUliLY8v","timestamp":1620778668997}]},"interpreter":{"hash":"e48d23369a553edc96f1373b6255b5687d82d68cd08867622b2500e338930542"},"kernelspec":{"display_name":"Python 3.7.3 64-bit ('base': conda)","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.11"}},"nbformat":4,"nbformat_minor":0}
