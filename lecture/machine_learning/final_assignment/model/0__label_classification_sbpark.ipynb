{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"iKqY7qXW3-OX"},"outputs":[],"source":["import pandas as pd\n","from konlpy.tag import Okt\n","import pickle\n","from tqdm import tqdm\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.svm import SVC\n","from sklearn.pipeline import Pipeline\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import classification_report\n","import numpy as np\n","from imblearn.under_sampling import RandomUnderSampler\n","from imblearn.over_sampling import RandomOverSampler\n","import numpy as np\n","from sklearn.tree import DecisionTreeClassifier\n","\n","tqdm.pandas()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ObV-a-on5Urf"},"outputs":[],"source":["def tokenizer(text):\n","    # divide Korean text into morpheme units\n","    okt = Okt()\n","\n","    return okt.morphs(text)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lwEj-IxL0ZOj"},"outputs":[],"source":["def load_data(path):\n","    df = pd.read_csv(path)\n","    # get only label column equals 0 or 1\n","    df = df[df.label != 2]\n","\n","    text_list = df[\"sentence\"].tolist()\n","    label_list = df[\"label\"].tolist()\n","\n","    return text_list, label_list"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L-dOpE2Dr9Vy"},"outputs":[],"source":["def split(text_list, label_list):\n","    text_train, text_test, label_train, label_test = train_test_split(text_list, label_list, test_size=0.2)\n","\n","    return text_train, text_test, label_train, label_test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VqlZa0Nms_Rs"},"outputs":[],"source":["def learn(X_train, X_test, y_train, y_test, model):\n","    # extract text feature with TfidfVectorizer\n","    tfidf = TfidfVectorizer(lowercase=False, tokenizer=tokenizer)\n","    # set linear support vector classifier \n","    svm = SVC(kernel=\"linear\", probability=True)\n","    # set an object containing overall processes\n","    pipe = Pipeline([(\"vect\", tfidf), (\"clf\", svm)])\n","    pipe.fit(X_train, y_train)\n","    y_pred = pipe.predict(X_test)\n","\n","    # get performance metrics\n","    print(f\"Test acc: \\n {accuracy_score(y_test, y_pred):.2f}\")\n","    print(f\"CLS report: \\n {classification_report(y_test, y_pred)}\")\n","\n","    # save model\n","    with open(model, \"wb\") as f:\n","        pickle.dump(pipe, f)\n","\n","    print(\"Model Saved\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def learn_dt(X_train, X_test, y_train, y_test, model):\n","    # extract text feature with TfidfVectorizer\n","    tfidf = TfidfVectorizer(lowercase=False, tokenizer=tokenizer)\n","    # set an object containing overall processes\n","    pipe = Pipeline([(\"vect\", tfidf), (\"clf\", DecisionTreeClassifier())])\n","    pipe.fit(X_train, y_train)\n","    y_pred = pipe.predict(X_test)\n","\n","    # get performance metrics\n","    print(f\"Test acc: \\n {accuracy_score(y_test, y_pred):.2f}\")\n","    print(f\"CLS report: \\n {classification_report(y_test, y_pred)}\")\n","\n","    # save model\n","    with open(model, \"wb\") as f:\n","        pickle.dump(pipe, f)\n","\n","    print(\"Model Saved\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WQwGCV8_uL5J"},"outputs":[],"source":["def test(model):\n","    # get saved model\n","    with open(model, \"rb\") as f:\n","        pipe = pickle.load(f)\n","\n","    while True:\n","        text = input(\"Please write report: \")\n","        if text == \"end\":\n","            break\n","\n","        str = [text]\n","        # get probability for each class\n","        r1 = np.max(pipe.predict_proba(str) * 100)\n","        # get prediction\n","        r2 = pipe.predict(str)[0]\n","\n","        print(\"Acc: \", r1)\n","        print(r2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5kl2MFJs1fe0"},"outputs":[],"source":["def tonumpy(text_list, label_list):\n","    # convert list to array\n","    X_imb, y_imb = np.array(text_list), np.array(label_list)\n","    X_imb, y_imb = X_imb.reshape((-1, 1)), y_imb.reshape((-1, 1))\n","\n","    return X_imb, y_imb"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4Bk8M6zu1_oJ"},"outputs":[],"source":["def tolist(X_samp):\n","    # convert array to list\n","    a = []\n","    for i in tqdm(X_samp):\n","        a.append(i[0])\n","\n","    return a"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[],"source":["\"\"\"    \n","\"kfold_cv\" function \n","This is a type of k-fold cross-validation. A single k-fold cross-validation is used with both a validation and test set. \n","\"\"\"\n","def kfold_cv(x, y):\n","    # list2np\n","    x, y = tonumpy(x, y)\n","    # Vectorized data\n","    tfidf = TfidfVectorizer(lowercase=False, tokenizer=tokenizer)\n","\n","    # K-Fold Cros Validation\n","    rand = np.random.choice(range(len(y)), len(y), replace=False)\n","    k1 = (rand[0:int(len(y)/5)])\n","    k2 = (rand[int(len(y)/5):2*int(len(y)/5)])\n","    k3 = (rand[2*int(len(y)/5):3*int(len(y)/5)+1])\n","    k4 = (rand[3*int(len(y)/5)+1:4*int(len(y)/5)+2])\n","    k5 = (rand[4*int(len(y)/5)+2:5*int(len(y)/5)+2])\n","    # fold\n","    folds = [k1, k2, k3, k4, k5]\n","    for k_idx, knum in enumerate(folds):\n","        x_test, y_test = x[knum], y[knum]\n","        x_train, y_train = np.delete(x, np.s_[knum], axis=0), np.delete(y, np.s_[knum], axis=0)\n","        # set an object containing overall processes\n","        pipe = Pipeline([(\"vect\", tfidf), (\"clf\", DecisionTreeClassifier())])\n","        # np2list\n","        x_train_lst = tolist(x_train)\n","        y_train_lst = tolist(y_train)\n","        x_test_lst  = tolist(x_test)\n","        # Fit & Predict\n","        pipe.fit(x_train_lst, y_train_lst)\n","        y_pred = pipe.predict(x_test_lst)\n","        # np2list\n","        y_pred_lst = list(y_pred)\n","        y_test_lst = list(y_test)\n","        # Check correction \n","        correction = 0\n","        for i in range(len(y_test_lst)):\n","            if y_pred_lst[i] == y_test_lst[i]:\n","                correction+=1  \n","        print('K-fold{}, Validation Score: {}% '.format(k_idx+1,correction/len(y_test)*100))"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"5xGC0VxTvSjk"},"outputs":[],"source":["def under_sampling(text_list, label_list):\n","    X_imb, y_imb = tonumpy(text_list, label_list)\n","    # sampling method that reduces the number of data in a class with a lot of data\n","    X_samp, y_samp = RandomUnderSampler(random_state=0).fit_resample(X_imb, y_imb)\n","\n","    return tolist(X_samp), y_samp.tolist()"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"nCZXNloB5YYQ"},"outputs":[],"source":["def over_sampling(text_list, label_list):\n","    X_imb, y_imb = tonumpy(text_list, label_list)\n","    # sampling method that increases the number of data of a class with less data\n","    X_samp, y_samp = RandomOverSampler(random_state=0).fit_resample(X_imb, y_imb)\n","\n","    return tolist(X_samp), y_samp.tolist()"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"zwh5YSWp2eKa"},"outputs":[],"source":["def train(model, mode: str):\n","    # return text: list and label: list\n","    text, label = load_data(path)\n","\n","    # select under or over sampling\n","    if mode == \"under_sampling\":\n","        text, label = under_sampling(text, label)\n","    if mode == \"over_sampling\":\n","        text, label = over_sampling(text, label)\n","\n","    # split dataset train and test set\n","    text_train, text_test, label_train, label_test = split(text, label)\n","    # learn(text_train, text_test, label_train, label_test, model)\n","    kfold_cv(text_train, label_train)"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"g6VsjQK79vux"},"outputs":[],"source":["def label_csv(model: str, unlabeled_path: str, save_path: str):\n","    # get unlabeled dataset\n","    df = pd.read_csv(unlabeled_path)\n","    # remove missing values\n","    df = df[df[\"sentence\"].notna()]\n","\n","    text_list = df[\"fixed\"].tolist()\n","\n","    # load model pipeline\n","    with open(model, \"rb\") as f:\n","        pipe = pickle.load(f)\n","\n","    p_label = []\n","    p_proba = []\n","\n","    for text in tqdm(text_list):\n","        str = [text]\n","        p_proba.append(np.max(pipe.predict_proba(str) * 100))\n","        p_label.append(pipe.predict(str)[0])\n","\n","    df[\"label\"] = p_label\n","    df[\"probability\"] = p_proba\n","\n","    df.to_csv(save_path, index=False, encoding=\"utf-8-sig\")\n","    print(\"Saved pseudo labeled .csv file\")"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"gxOQmX6CMPiO"},"outputs":[],"source":["df = pd.read_csv(\"database/new_split_labeling_1123.csv\", index_col = 0)\n","df.drop([\"reviewID\"], axis=1, inplace=True)\n","\n","df[-5:]"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":156358,"status":"ok","timestamp":1620782581546,"user":{"displayName":"이재리","photoUrl":"","userId":"07799536652921530236"},"user_tz":-540},"id":"MYt2S5le8Rvl","outputId":"245f2d43-96f4-4061-d4ff-052295e8846e"},"outputs":[],"source":["# training step with over sampling\n","# path = \"database/new_split_labeling.csv\"\n","# train(model=\"over.pkl\", mode=\"over_sampling\")"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 15150/15150 [00:00<00:00, 302039.65it/s]\n","100%|██████████| 9696/9696 [00:00<00:00, 297970.97it/s]\n","100%|██████████| 9696/9696 [00:00<00:00, 950053.07it/s]\n","100%|██████████| 2424/2424 [00:00<00:00, 294866.38it/s]\n"]},{"name":"stdout","output_type":"stream","text":["K-fold1, Validation Score: 82.75577557755776% \n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 9696/9696 [00:00<00:00, 216700.53it/s]\n","100%|██████████| 9696/9696 [00:00<00:00, 1022347.76it/s]\n","100%|██████████| 2424/2424 [00:00<00:00, 322505.72it/s]\n"]},{"name":"stdout","output_type":"stream","text":["K-fold2, Validation Score: 83.16831683168317% \n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 9695/9695 [00:00<00:00, 326879.24it/s]\n","100%|██████████| 9695/9695 [00:00<00:00, 859063.64it/s]\n","100%|██████████| 2425/2425 [00:00<00:00, 190614.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["K-fold3, Validation Score: 81.15463917525774% \n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 9695/9695 [00:00<00:00, 316336.39it/s]\n","100%|██████████| 9695/9695 [00:00<00:00, 967724.35it/s]\n","100%|██████████| 2425/2425 [00:00<00:00, 324036.68it/s]\n"]},{"name":"stdout","output_type":"stream","text":["K-fold4, Validation Score: 83.25773195876288% \n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 9698/9698 [00:00<00:00, 311200.23it/s]\n","100%|██████████| 9698/9698 [00:00<00:00, 973165.23it/s]\n","100%|██████████| 2422/2422 [00:00<00:00, 322710.51it/s]\n"]},{"name":"stdout","output_type":"stream","text":["K-fold5, Validation Score: 81.87448389760529% \n"]}],"source":["# training step with under sampling\n","path = \"database/new_split_labeling_1123.csv\"\n","train(model=\"under.pkl\", mode=\"under_sampling\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# write overall file with label\n","# label_csv(model=\"../model/over.pkl\", unlabeled_path=\"../database/tokenized_review_unlabel.csv\", save_path=\"../database/tokenized_review_label.csv\")"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMDvaSBFgzGS5n4rKGUq8+X","collapsed_sections":[],"mount_file_id":"1pAFRAnoENjvVpXVLwKwdEXjVvMKX6H2J","name":"label.ipynb","provenance":[{"file_id":"1YdGp_lYv8DQL9RXWXuGs6896xUliLY8v","timestamp":1620778668997}]},"interpreter":{"hash":"a41e22708aa9bd393670ec3a27caa2eb8abf3a0d7d03b2aafad474dc9f6f31ae"},"kernelspec":{"display_name":"Python 3.8.8 64-bit ('rilab': pyenv)","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":0}
